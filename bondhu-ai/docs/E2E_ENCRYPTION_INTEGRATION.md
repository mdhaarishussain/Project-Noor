# End-to-End Encryption Integration Plan

## Current System Architecture

### Message Flow
1. **Client sends message** â†’ API endpoint
2. **API processes message**:
   - Extracts memories
   - Retrieves conversation context
   - Gets chat history (last 15 messages)
   - Sends to Gemini service
3. **Gemini service**:
   - Analyzes mood/sentiment
   - Creates system prompt
   - Includes conversation history
   - Generates response
4. **API stores messages**:
   - User message
   - AI response
   - Invalidates Redis cache
5. **Client retrieves history**:
   - From Redis cache (if available)
   - From database (if not cached)

### Key Components
- **Supabase**: Stores chat messages, user memories, conversation summaries
- **Redis**: Caches chat history for performance
- **Gemini Service**: Processes messages with context
- **Memory System**: Manages user facts and conversation summaries

## Encryption Integration Challenges

### 1. Client-Side Encryption vs. LLM Processing
**Problem**: LLM needs plaintext to understand context, but we want E2E encryption
**Solution**: Hybrid approach - encrypt at rest, decrypt for processing

### 2. Context Retrieval for LLM
**Problem**: LLM needs last 15 messages for context, but they're encrypted
**Solution**: Decrypt messages when retrieving for LLM context

### 3. Redis Cache Integration
**Problem**: Cache stores messages that should be encrypted
**Solution**: Encrypt before caching, decrypt when retrieving

### 4. Memory System Integration
**Problem**: Conversation summaries reference encrypted content
**Solution**: Create summaries from decrypted content, then encrypt storage

## Proposed Solution: Hybrid Encryption Approach

### Encryption Strategy
1. **In-Transit**: TLS/SSL (already implemented)
2. **At-Rest**: Client-side encryption before storage
3. **In-Processing**: Temporary decryption for LLM context
4. **In-Cache**: Encrypted storage in Redis

### Key Management
1. **User Key Pairs**: RSA-2048 for each user
2. **Session Keys**: AES-256 for each conversation session
3. **Key Storage**: Public keys in database, private keys on client

## Implementation Plan

### Phase 1: Infrastructure Setup

#### 1. Database Schema Updates
```sql
-- Add encryption metadata to chat_messages table
ALTER TABLE chat_messages 
ADD COLUMN IF NOT EXISTS is_encrypted BOOLEAN DEFAULT FALSE,
ADD COLUMN IF NOT EXISTS encryption_version INTEGER DEFAULT 1,
ADD COLUMN IF NOT EXISTS session_key_encrypted TEXT,
ADD COLUMN IF NOT EXISTS nonce TEXT;

-- Create user_keys table
CREATE TABLE IF NOT EXISTS user_keys (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    user_id UUID NOT NULL REFERENCES auth.users(id) ON DELETE CASCADE,
    public_key TEXT NOT NULL,
    key_type TEXT NOT NULL DEFAULT 'RSA-2048',
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW()
);
```

#### 2. Encryption Service
Already created in `core/security/encryption.py`

### Phase 2: Message Storage Encryption

#### 1. Modified Storage Logic
```python
# In _store_chat_message function
async def store_encrypted_message(
    user_id: str,
    message: str,
    is_user_message: bool,
    session_id: Optional[str],
    # ... other params
):
    # 1. Generate session key if needed
    # 2. Encrypt message content
    # 3. Encrypt session key with recipient's public key
    # 4. Store encrypted data in database
    
    encrypted_content, nonce = encrypt_message(message, session_key)
    encrypted_session_key = encrypt_with_rsa(session_key, recipient_public_key)
    
    # Store in database
    supabase.supabase.table('chat_messages').insert({
        'user_id': user_id,
        'message_text': encrypted_content.hex(),  # Store as hex
        'sender_type': 'user' if is_user_message else 'ai',
        'is_encrypted': True,
        'nonce': nonce.hex(),
        'session_key_encrypted': encrypted_session_key.hex(),
        'session_id': session_id
    }).execute()
```

### Phase 3: Context Retrieval Decryption

#### 1. Modified History Retrieval
```python
# In get_chat_history function (Gemini service)
async def get_chat_history_for_context(
    self, 
    user_id: str, 
    session_id: Optional[str] = None,
    limit: int = 20
) -> list[Dict[str, Any]]:
    # 1. Retrieve encrypted messages from database
    # 2. Decrypt messages for LLM context
    # 3. Return decrypted content for processing
    
    try:
        # Get user's private key (from secure client storage in real implementation)
        # For now, we'll need to handle this differently
        
        response = query.order("timestamp", desc=True).limit(limit).execute()
        
        history = []
        for msg in reversed(response.data):
            content = msg["message_text"]
            
            # Decrypt if encrypted
            if msg.get("is_encrypted"):
                decrypted_content = decrypt_message_for_context(
                    content, 
                    msg.get("nonce"), 
                    msg.get("session_key_encrypted"),
                    user_id
                )
                content = decrypted_content
            
            history.append({
                "role": msg["sender_type"],
                "content": content
            })
        
        return history
    except Exception as e:
        logger.error(f"Error retrieving chat history: {e}")
        return []
```

### Phase 4: Redis Cache Integration

#### 1. Encrypted Cache Storage
```python
# When caching chat history
async def cache_encrypted_chat_history(
    user_id: str,
    messages: list[ChatMessage],
    limit: int,
    offset: int
):
    redis = get_redis()
    cache_key = get_chat_history_cache_key(user_id, limit, offset)
    
    # Encrypt messages before caching
    encrypted_messages = []
    for msg in messages:
        encrypted_msg = msg.copy()
        if not msg.is_encrypted:
            # Encrypt for cache storage
            encrypted_content = encrypt_for_cache(msg.message_text)
            encrypted_msg.message_text = encrypted_content
            encrypted_msg.is_encrypted = True
        encrypted_messages.append(encrypted_msg)
    
    # Cache encrypted messages
    cache_data = {
        'messages': [msg.dict() for msg in encrypted_messages],
        'total': len(messages),
        'user_id': user_id
    }
    redis.setex(cache_key, CHAT_HISTORY_CACHE_TTL, json.dumps(cache_data))
```

#### 2. Decrypted Cache Retrieval
```python
# When retrieving from cache
async def get_decrypted_chat_history_from_cache(
    user_id: str,
    limit: int,
    offset: int
) -> Optional[list[ChatMessage]]:
    redis = get_redis()
    cache_key = get_chat_history_cache_key(user_id, limit, offset)
    
    cached_data = redis.get(cache_key)
    if cached_data:
        data = json.loads(cached_data)
        messages = [ChatMessage(**msg_data) for msg_data in data['messages']]
        
        # Decrypt messages for use
        decrypted_messages = []
        for msg in messages:
            if msg.is_encrypted:
                decrypted_msg = msg.copy()
                decrypted_msg.message_text = decrypt_from_cache(msg.message_text)
                decrypted_msg.is_encrypted = False
                decrypted_messages.append(decrypted_msg)
            else:
                decrypted_messages.append(msg)
        
        return decrypted_messages
    
    return None
```

### Phase 5: Memory System Integration

#### 1. Conversation Summary Creation
```python
# In conversation_memory.py
async def create_encrypted_conversation_memory(
    self,
    user_id: str,
    session_id: str
):
    # 1. Get messages for session (decrypted for processing)
    messages = get_decrypted_messages_for_session(user_id, session_id)
    
    # 2. Create summary from decrypted content
    summary = create_summary_from_messages(messages)
    
    # 3. Store encrypted summary
    encrypted_summary = encrypt_summary(summary)
    
    # 4. Store in database
    self._client.supabase.table("conversation_memories").insert({
        "user_id": user_id,
        "session_id": session_id,
        "conversation_summary": encrypted_summary,
        # ... other fields
    }).execute()
```

## Security Considerations

### 1. Key Management
- Private keys must NEVER be stored on the server
- Public keys stored in `user_keys` table
- Session keys encrypted with recipient's public key

### 2. Data Processing
- Messages decrypted only when needed for LLM processing
- Decrypted data never logged or stored
- Secure memory handling

### 3. Cache Security
- Encrypted storage in Redis
- Cache invalidation maintains security
- TTL-based expiration

### 4. Backward Compatibility
- Unencrypted messages marked with `is_encrypted = FALSE`
- Gradual migration of existing data
- Fallback handling for mixed encryption states

## Implementation Challenges

### 1. Client-Side Key Management
**Issue**: Private keys need to be on client devices
**Solution**: Implement client-side key generation and secure storage

### 2. Server-Side Decryption
**Issue**: Server needs to decrypt for LLM processing
**Solution**: Hybrid approach - decrypt only for processing, re-encrypt for storage

### 3. Performance Impact
**Issue**: Encryption/decryption adds overhead
**Solution**: Optimize critical paths, use caching strategically

## Rollout Strategy

### Phase 1: Backend Infrastructure (2 weeks)
- Database schema updates
- Encryption service refinement
- API endpoint modifications

### Phase 2: Client Integration (4 weeks)
- Client-side encryption implementation
- Key management UI
- Testing with internal users

### Phase 3: Gradual Rollout (2 weeks)
- Opt-in for new conversations
- Migration of existing conversations
- Full deployment

## Testing Plan

### 1. Unit Tests
- Encryption/decryption functions
- Key management operations
- Database integration

### 2. Integration Tests
- End-to-end message flow
- Context retrieval and processing
- Cache integration

### 3. Security Audits
- Penetration testing
- Code review
- Compliance verification

## Monitoring and Metrics

### 1. Security Metrics
- Encryption success rates
- Key rotation events
- Security incident tracking

### 2. Performance Metrics
- Encryption/decryption latency
- Cache hit rates
- Overall response times

### 3. User Experience
- Message delivery success
- Error handling
- User feedback
